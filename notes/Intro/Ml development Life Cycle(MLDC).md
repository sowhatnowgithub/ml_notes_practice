**1.Frame the Problem** 
	
**2.Gathering Data,** 
	At school and college level, we can find data from kaggle, but we can't find these easily at a entriprise level
	1.CSV
	2.API
	3.Web scraping
	4.DataBase - this is an active database hence can't build directly on the model.
	We use the data from dataWarehouse,  by extracting from active databases
	
**3.Data Preprocessing -** Cleaning of Data
	1.Remove Duplicates
	2.Missing Values
	3.Outliers
	4.Scale / Standardization
	
**4.Exploratory Data Analysis (EDA)**
	Extract relations
	1.Visulation 
	2. Univariante , bivariante, multivariante
	3.Outlier detection
	4.Imbalance data to balance data. 
	
**5.Featuring Engineering and Selection**
	1.We will replace the columms with relation as one
	2.We will remove the unwanted 

**6.Model Training, Evaluation and Selection**
	1.We will use multiple models, and see the results
	2.Performance metrics
	3.We will now select the algortihm and tune the parameters
	4.Ensemble learning - we use multiple models and combine them to create a better models.

**7.Model Deployment**

**8.Testing**
	1.Beta testing
	2.A/B testing
	
**9.Optimize**
	1.Backup
	2.Data
	3.Retrain the model as there is a chance of rotting
	
	
	